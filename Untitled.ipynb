{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import robot\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_L: x(b x dim)->l(b x ndim*(ndim+1)/2)\n",
    "# net_g: x(b x dim)->g(b x ndim)\n",
    "# q(b x ndim)--net-->l(b x ndim*(ndim+1)/2)--reshape-->L(b x ndim x ndim,lower triangle), dLdq(b x ndim x ndim x ndim, lower triangle)\n",
    "# dLdt(b x ndim x ndim)\n",
    "# dHdt(b x ndim x ndim)\n",
    "# dHdq(b x ndim x ndim x ndim)\n",
    "\n",
    "def get_batch_jacobian(net, x, noutputs):\n",
    "    x = x.unsqueeze(1)\n",
    "    n = x.size()[0]\n",
    "    x = x.repeat(1, noutputs, 1)\n",
    "    x.requires_grad_(True)\n",
    "    y = net(x)\n",
    "    input_val = torch.eye(noutputs).reshape(1,noutputs, noutputs).repeat(n, 1, 1)\n",
    "    x.retain_grad()\n",
    "    y.backward(input_val)\n",
    "    return y[:,0,:], x.grad.data\n",
    "\n",
    "\n",
    "def get_LdLdq(net, q):\n",
    "    nbatch=q.shape[0]\n",
    "    ndim=q.shape[1]\n",
    "    l, l_jac=get_batch_jacobian(net, q, int(ndim*(ndim+1)/2))\n",
    "    L = torch.zeros((nbatch, ndim, ndim))\n",
    "    tril_indices = torch.tril_indices(row=ndim, col=ndim, offset=0)\n",
    "    L[:,tril_indices[0], tril_indices[1]] = l\n",
    "    dLdq=torch.zeros((nbatch, ndim, ndim, ndim))\n",
    "    dLdq[:,tril_indices[0], tril_indices[1],:]=l_jac\n",
    "    return L, dLdq\n",
    "\n",
    "def inverse_model(net_L, net_g, q, dq, ddq):\n",
    "    nbatch=q.shape[0]\n",
    "    ndim=q.shape[1]\n",
    "    l, l_jac=get_batch_jacobian(net_L, q, int(ndim*(ndim+1)/2))\n",
    "    L = torch.zeros((nbatch, ndim, ndim))\n",
    "    tril_indices = torch.tril_indices(row=ndim, col=ndim, offset=0)\n",
    "    L[:,tril_indices[0], tril_indices[1]] = l\n",
    "    dLdq=torch.zeros((nbatch, ndim, ndim, ndim))\n",
    "    dLdq[:,tril_indices[0], tril_indices[1],:]=l_jac\n",
    "    dLdt=(dLdq@dq.unsqueeze(2)).squeeze()\n",
    "    H=L@L.transpose(1,2)\n",
    "    dHdt=L@dLdt.transpose(1,2)+dLdt@L.transpose(1,2)\n",
    "    dHdq=dLdq.permute(0,3,1,2)@L.transpose(1,2)+L@dLdq.permute(0,3,2,1)\n",
    "    quad=((dq.unsqueeze(1)@dHdq)@dq.unsqueeze(2)).squeeze() # d(dqHdq)dq\n",
    "    tau=(H@ddq.unsqueeze(2)).squeeze()+(dHdt@dq.unsqueeze(2)).squeeze()-0.5*quad+net_g(q)\n",
    "    return tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModule(nn.Module):\n",
    "    # Test module only for ndim=3\n",
    "    def __init__(self):\n",
    "        super(TestModule, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.cat([torch.exp(x),torch.exp(2*x)],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=TestModule()\n",
    "\n",
    "q=torch.stack([torch.log(torch.arange(1,4).float()),torch.log(torch.arange(2,5).float()),torch.log(torch.arange(5,8).float())])\n",
    "dq=torch.ones(q.shape)\n",
    "ddq=torch.ones(q.shape)\n",
    "\n",
    "\n",
    "L,dLdq=get_LdLdq(model,q)\n",
    "dLdt=(dLdq@dq.unsqueeze(2)).squeeze()\n",
    "H=L@L.transpose(1,2)\n",
    "dHdt=L@dLdt.transpose(1,2)+dLdt@L.transpose(1,2)\n",
    "dHdq=dLdq.permute(0,3,1,2)@L.transpose(1,2)+L@dLdq.permute(0,3,2,1)\n",
    "quad=((dq.unsqueeze(1)@dHdq)@dq.unsqueeze(2)).squeeze() # d(dqHdq)dq\n",
    "\n",
    "tau=(H@ddq.unsqueeze(2)).squeeze()+(dHdt@dq.unsqueeze(2)).squeeze()-0.5*quad+model_g(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_L=TestModule()\n",
    "model_g=nn.Linear(3,3)\n",
    "q=torch.stack([torch.log(torch.arange(1,4).float()),torch.log(torch.arange(2,5).float()),torch.log(torch.arange(5,8).float())])\n",
    "dq=torch.ones(q.shape)\n",
    "ddq=torch.ones(q.shape)\n",
    "\n",
    "tau=inverse_model(model_L, model_g, q,dq,ddq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(3, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Sequential(\n",
    "        nn.Softplus(),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.ReLU(),\n",
    "    ),\n",
    "    nn.Linear(256, 256),\n",
    "    nn.Softplus(),\n",
    "    nn.Linear(256, 6),\n",
    ")\n",
    "\n",
    "x = torch.rand((1, 3)).requires_grad_(True)\n",
    "\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RobotArm test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default glsl path /home/derek/anaconda3/lib/python3.7/site-packages/sapien/glsl_shader/130\n",
      "USE sapien core\n"
     ]
    }
   ],
   "source": [
    "from gym.wrappers import TimeLimit\n",
    "from robot.envs.hyrule.rl_env import ArmReachWithXYZ\n",
    "import numpy as np\n",
    "from robot.model.arm.extra import lagrangian_v2 as lg\n",
    "from torch import nn\n",
    "import torch\n",
    "from robot.model.arm.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default glsl path /home/derek/anaconda3/lib/python3.7/site-packages/sapien/glsl_shader/130\n",
      "USE sapien core\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/derek/git/Robotics/robot/model/arm/envs/arm_controller.py:32: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  delta = np.linalg.lstsq(jac[:3], goal-achieved)[0] * 10 # desired_velocity\n",
      "/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/derek/git/Robotics/robot/model/arm/envs/arm_controller.py:32: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  delta = np.linalg.lstsq(jac[:3], goal-achieved)[0] * 10 # desired_velocity\n",
      "/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/derek/git/Robotics/robot/model/arm/envs/arm_controller.py:32: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  delta = np.linalg.lstsq(jac[:3], goal-achieved)[0] * 10 # desired_velocity\n",
      "/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/derek/git/Robotics/robot/model/arm/envs/arm_controller.py:32: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  delta = np.linalg.lstsq(jac[:3], goal-achieved)[0] * 10 # desired_velocity\n",
      "/home/derek/git/Robotics/robot/model/arm/envs/arm_controller.py:32: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  delta = np.linalg.lstsq(jac[:3], goal-achieved)[0] * 10 # desired_velocity\n",
      "/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/derek/git/Robotics/robot/model/arm/envs/arm_controller.py:32: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  delta = np.linalg.lstsq(jac[:3], goal-achieved)[0] * 10 # desired_velocity\n",
      "/home/derek/git/Robotics/robot/model/arm/envs/arm_controller.py:32: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  delta = np.linalg.lstsq(jac[:3], goal-achieved)[0] * 10 # desired_velocity\n",
      "/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/derek/git/Robotics/robot/model/arm/envs/arm_controller.py:32: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  delta = np.linalg.lstsq(jac[:3], goal-achieved)[0] * 10 # desired_velocity\n",
      "/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/derek/git/Robotics/robot/model/arm/envs/arm_controller.py:32: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  delta = np.linalg.lstsq(jac[:3], goal-achieved)[0] * 10 # desired_velocity\n",
      "/home/derek/git/Robotics/robot/model/arm/envs/arm_controller.py:32: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  delta = np.linalg.lstsq(jac[:3], goal-achieved)[0] * 10 # desired_velocity\n",
      "  0%|          | 1/5000 [00:00<1:02:53,  1.32it/s]/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/derek/git/Robotics/robot/model/arm/envs/arm_controller.py:32: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  delta = np.linalg.lstsq(jac[:3], goal-achieved)[0] * 10 # desired_velocity\n",
      "/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/derek/git/Robotics/robot/model/arm/envs/arm_controller.py:32: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  delta = np.linalg.lstsq(jac[:3], goal-achieved)[0] * 10 # desired_velocity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/derek/git/Robotics/robot/model/arm/envs/arm_controller.py:32: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  delta = np.linalg.lstsq(jac[:3], goal-achieved)[0] * 10 # desired_velocity\n",
      "/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/derek/git/Robotics/robot/model/arm/envs/arm_controller.py:32: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  delta = np.linalg.lstsq(jac[:3], goal-achieved)[0] * 10 # desired_velocity\n",
      "/home/derek/git/Robotics/robot/model/arm/envs/arm_controller.py:32: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  delta = np.linalg.lstsq(jac[:3], goal-achieved)[0] * 10 # desired_velocity\n",
      " 76%|███████▋  | 3824/5000 [44:15<12:38,  1.55it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...  ./dataset/arm/11.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 3828/5000 [44:17<10:50,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...  ./dataset/arm/13.pkl\n",
      "saving...  ./dataset/arm/10.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 3832/5000 [44:19<12:29,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...  ./dataset/arm/14.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 3835/5000 [44:21<10:51,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...  ./dataset/arm/12.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 3945/5000 [45:36<11:35,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...  ./dataset/arm/9.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 4066/5000 [46:57<11:25,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...  ./dataset/arm/8.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 4179/5000 [48:14<09:17,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...  ./dataset/arm/7.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 4293/5000 [49:27<07:32,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...  ./dataset/arm/6.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 4359/5000 [50:10<06:57,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...  ./dataset/arm/5.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 4421/5000 [50:45<06:13,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...  ./dataset/arm/4.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 4517/5000 [51:44<04:51,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...  ./dataset/arm/3.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 4596/5000 [52:32<04:23,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...  ./dataset/arm/2.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 4694/5000 [53:30<02:52,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...  ./dataset/arm/1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 4792/5000 [54:27<02:17,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...  ./dataset/arm/0.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 4915/5000 [55:33<00:30,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...  ./dataset/arm/18.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 4925/5000 [55:38<00:40,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...  ./dataset/arm/17.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 4938/5000 [55:44<00:26,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...  ./dataset/arm/15.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 4948/5000 [55:49<00:22,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...  ./dataset/arm/16.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [56:16<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...  ./dataset/arm/19.pkl\n"
     ]
    }
   ],
   "source": [
    "make_dataset('arm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0000000e+00 -1.3825793e+00 -2.9427279e-02  5.7432674e-02\n",
      " -9.7876757e-01  3.7991413e-01  6.0942268e-01  2.4935515e+00\n",
      "  8.0001003e-01  8.0001003e-01  8.0000019e-01  1.1211396e-13\n",
      "  3.5619316e-12 -1.8626451e-09 -6.7977220e-02 -1.1120176e+00\n",
      "  2.8683582e-01 -1.0252906e+00 -2.1472794e-01  7.6243766e-02\n",
      "  2.1023731e-01  1.1284603e-05  1.0477379e-09 -1.4394755e-06\n",
      "  4.8441251e-12  0.0000000e+00 -1.2245178e-03 -1.9696816e+00\n",
      " -2.1866995e+01  6.0620375e+00 -1.8629780e+01 -4.7180300e+00\n",
      "  2.4600406e+00  5.1464810e+00  1.8125772e-03 -5.9604645e-06\n",
      "  1.0341406e-05  3.6397523e-08  5.2817632e-07  8.8724220e-01\n",
      "  3.2058075e-02  1.2223468e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derek/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env=TimeLimit(ArmReachWithXYZ(), 50)\n",
    "obs=env.reset()\n",
    "print(obs['observation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in env.agent.get_joints():\n",
    "    print(i.name)\n",
    "    \n",
    "actuator=['right_shoulder_pan_joint',\n",
    "                          'right_shoulder_lift_joint',\n",
    "                          'right_arm_half_joint',\n",
    "                          'right_elbow_joint',\n",
    "                          'right_wrist_spherical_1_joint',\n",
    "                          'right_wrist_spherical_2_joint',\n",
    "                          'right_wrist_3_joint',\n",
    "                          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX ACTION [1. 1. 1. 1. 1. 1. 1.]\n",
      "MAX Q [6.28318214 2.47949553 6.28318214 6.13466597 6.28318501 2.6306982\n",
      " 6.28317213]\n",
      "MAX DQ [ 494.97387695  102.62372589  481.76843262  259.27737427 1409.93457031\n",
      "  554.1619873  1217.09179688]\n",
      "num train 80000\n",
      "num valid 20000\n"
     ]
    }
   ],
   "source": [
    "from gym.wrappers import TimeLimit\n",
    "from robot.envs.hyrule.rl_env import ArmReachWithXYZ\n",
    "import numpy as np\n",
    "from robot.model.arm.extra import lagrangian_v2 as lg\n",
    "from torch import nn\n",
    "import torch\n",
    "from robot.model.arm.dataset import *\n",
    "dataset=Dataset('./dataset/arm', device='cuda:3')\n",
    "\n",
    "def get_info(data):\n",
    "    q=data[0][:,1,1:8]\n",
    "    dq=data[0][:,1,14:21]\n",
    "    ddq=data[0][:,1,27:34]\n",
    "    return q, dq, ddq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device('cuda:3')\n",
    "\n",
    "# model_l = nn.Sequential(\n",
    "#     nn.Linear(7, 256),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(256, 256),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(256, 256),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(256, 256),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(256, 28),\n",
    "# )\n",
    "\n",
    "# model_g = nn.Sequential(\n",
    "#     nn.Linear(7, 256),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(256, 256),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(256, 256),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(256, 256),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(256, 7),\n",
    "# )\n",
    "\n",
    "class LagModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, ndim):\n",
    "        super(LagModel, self).__init__()\n",
    "        self.feat=nn.Sequential(\n",
    "            nn.Linear(ndim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.diag=nn.Sequential(\n",
    "            nn.Linear(256, ndim),\n",
    "#             nn.ReLU(),\n",
    "        )\n",
    "        self.tril=nn.Linear(256, int(ndim*(ndim-1)/2))\n",
    "        self.gravity=nn.Linear(256, ndim)\n",
    "        \n",
    "    def forward(self, q):\n",
    "        feature=self.feat(q)\n",
    "        out=torch.cat([self.tril(feature), self.diag(feature)], dim=-1)\n",
    "        return out, self.gravity(feature)\n",
    "        \n",
    "model_lag=LagModel(7)      \n",
    "model_naive = nn.Sequential(\n",
    "    nn.Linear(21, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 7),\n",
    "\n",
    ")\n",
    "\n",
    "model_generator=LagModel(7)\n",
    "model_generator=model_generator.cuda()\n",
    "\n",
    "# model_l=model_l.cuda()\n",
    "# model_g=model_g.cuda()\n",
    "model_lag=model_lag.cuda()\n",
    "model_naive=model_naive.cuda()\n",
    "crit = nn.MSELoss()\n",
    "\n",
    "\n",
    "train_loss_lag=[]\n",
    "train_loss_naive=[]\n",
    "val_loss_lag=[]\n",
    "val_loss_naive=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1689.92822265625 21548.4375\n",
      "0 1 1149.251708984375 14343.0556640625\n",
      "0 2 2594.150146484375 5165.333984375\n",
      "0 3 667.4290771484375 4364.5166015625\n",
      "0 4 826.2850952148438 3985.76171875\n",
      "0 5 980.0744018554688 3315.215087890625\n",
      "0 6 556.5008544921875 5556.27685546875\n",
      "0 7 415.4665222167969 2671.2265625\n",
      "0 8 1224.758544921875 4887.533203125\n",
      "0 9 417.32720947265625 3339.4755859375\n",
      "0 10 793.4598388671875 3376.645751953125\n",
      "0 11 1125.57470703125 13526.5693359375\n",
      "0 12 686.3563232421875 2505.206787109375\n",
      "0 13 1097.1552734375 3078.85400390625\n",
      "0 14 324.2840576171875 1599.1400146484375\n",
      "0 15 498.485107421875 1888.528076171875\n",
      "0 16 543.4044799804688 2317.162841796875\n",
      "0 17 382.64349365234375 2502.919677734375\n",
      "0 18 434.55023193359375 2146.846435546875\n",
      "0 19 305.61627197265625 3263.9716796875\n",
      "0 20 162.92697143554688 1495.4925537109375\n",
      "0 21 363.69195556640625 2054.06396484375\n",
      "0 22 304.6307373046875 2277.99658203125\n",
      "0 23 408.9666748046875 2235.634765625\n",
      "0 24 397.4864501953125 1627.51806640625\n",
      "0 25 310.6122131347656 1187.597412109375\n",
      "0 26 374.2477111816406 1002.26220703125\n",
      "0 27 335.60833740234375 1289.0120849609375\n",
      "0 28 506.5876770019531 1891.683349609375\n",
      "0 29 196.9789276123047 1411.5565185546875\n",
      "0 30 186.7541961669922 993.0940551757812\n",
      "0 31 335.0867919921875 1138.7991943359375\n",
      "0 32 320.0646667480469 998.275146484375\n",
      "0 33 367.23626708984375 1801.76513671875\n",
      "0 34 263.9677429199219 1158.7181396484375\n",
      "0 35 280.2976989746094 1175.3763427734375\n",
      "0 36 230.9764862060547 923.7041625976562\n",
      "0 37 269.853515625 706.7579956054688\n",
      "0 38 176.31561279296875 677.256103515625\n",
      "0 39 274.20220947265625 918.1012573242188\n",
      "0 40 219.6697235107422 1058.096923828125\n",
      "0 41 237.5084228515625 1169.28857421875\n",
      "0 42 207.66488647460938 734.1995239257812\n",
      "0 43 223.49176025390625 822.9987182617188\n",
      "0 44 598.0167236328125 1642.71826171875\n",
      "0 45 286.273681640625 929.25927734375\n",
      "0 46 160.5928497314453 808.1627197265625\n",
      "0 47 190.1179656982422 873.5664672851562\n",
      "0 48 262.82550048828125 760.1836547851562\n",
      "0 49 193.40005493164062 581.3583984375\n",
      "0 50 245.88134765625 987.9794921875\n",
      "0 51 194.78367614746094 754.5304565429688\n",
      "0 52 198.06871032714844 687.1475219726562\n",
      "0 53 351.7831726074219 1427.3348388671875\n",
      "0 54 154.20553588867188 635.3414306640625\n",
      "0 55 372.1549377441406 920.5073852539062\n",
      "0 56 137.47500610351562 437.40618896484375\n",
      "0 57 711.2815551757812 1674.947998046875\n",
      "0 58 351.0182189941406 1079.311767578125\n",
      "0 59 212.61782836914062 725.0943603515625\n",
      "0 60 403.3809814453125 883.962646484375\n",
      "0 61 173.04605102539062 652.1902465820312\n",
      "0 62 273.4256591796875 851.5067138671875\n",
      "0 63 889.3729248046875 1175.4088134765625\n",
      "0 64 285.6546630859375 555.0929565429688\n",
      "0 65 265.1021423339844 1703.07861328125\n",
      "0 66 211.59288024902344 566.0006103515625\n",
      "0 67 329.0613708496094 570.9293823242188\n",
      "0 68 269.808349609375 834.338623046875\n",
      "0 69 215.73138427734375 653.2412109375\n",
      "0 70 291.3565368652344 925.9307861328125\n",
      "0 71 122.47636413574219 767.3245239257812\n",
      "0 72 295.9308776855469 732.7254638671875\n",
      "0 73 245.6139678955078 624.9962768554688\n",
      "0 74 170.27703857421875 860.4297485351562\n",
      "0 75 190.33433532714844 929.179443359375\n",
      "0 76 230.8565216064453 613.281005859375\n",
      "0 77 116.74476623535156 499.0593566894531\n",
      "0 78 188.59848022460938 787.4317016601562\n",
      "0 79 297.3412780761719 928.995849609375\n",
      "0 80 257.2131652832031 755.9202270507812\n",
      "0 81 216.1670684814453 1592.668212890625\n",
      "0 82 229.1282958984375 805.2034301757812\n",
      "0 83 228.7661590576172 1022.8636474609375\n",
      "0 84 234.0085906982422 748.5158081054688\n",
      "0 85 186.35377502441406 660.8387451171875\n",
      "0 86 237.142578125 975.6095581054688\n",
      "0 87 226.6741180419922 718.5079956054688\n",
      "0 88 169.69497680664062 563.3728637695312\n",
      "0 89 175.93569946289062 610.6668090820312\n",
      "0 90 168.7101287841797 633.6910400390625\n",
      "0 91 423.9434814453125 1499.855224609375\n",
      "0 92 502.76544189453125 1760.6917724609375\n",
      "0 93 304.768310546875 784.531005859375\n",
      "0 94 169.6555938720703 702.5660400390625\n",
      "0 95 274.1869812011719 971.3511962890625\n",
      "0 96 216.64053344726562 479.9973449707031\n",
      "0 97 207.68133544921875 473.0298767089844\n",
      "0 98 181.58934020996094 934.2267456054688\n",
      "0 99 573.0264892578125 1583.2064208984375\n",
      "0 100 191.17257690429688 455.13897705078125\n",
      "0 101 150.79258728027344 796.440673828125\n",
      "0 102 182.7175750732422 713.042236328125\n",
      "0 103 172.15444946289062 698.956787109375\n",
      "0 104 206.52804565429688 568.7874755859375\n",
      "0 105 127.82395935058594 498.3128356933594\n",
      "0 106 241.15847778320312 1137.7593994140625\n",
      "0 107 240.7555694580078 984.9542846679688\n",
      "0 108 119.60523986816406 1002.6907348632812\n",
      "0 109 436.9280700683594 1021.9181518554688\n",
      "0 110 131.09039306640625 520.5158081054688\n",
      "0 111 211.7714385986328 1060.43212890625\n",
      "0 112 328.6642761230469 793.6336669921875\n",
      "0 113 182.1773223876953 621.2813720703125\n",
      "0 114 244.1736297607422 760.0753784179688\n",
      "0 115 617.8342895507812 1115.060302734375\n",
      "0 116 157.83364868164062 559.1404418945312\n",
      "0 117 437.5919494628906 1268.284912109375\n",
      "0 118 190.9774932861328 847.5360107421875\n",
      "0 119 309.2975158691406 1163.0850830078125\n",
      "0 120 340.1452331542969 756.6778564453125\n",
      "0 121 286.9378356933594 1137.603271484375\n",
      "0 122 134.91514587402344 682.7522583007812\n",
      "0 123 322.2516174316406 688.6870727539062\n",
      "0 124 195.55308532714844 700.9887084960938\n",
      "0 125 155.67373657226562 518.3719482421875\n",
      "0 126 193.52732849121094 738.3320922851562\n",
      "0 127 1051.86865234375 2153.272705078125\n",
      "0 128 243.14276123046875 782.9771728515625\n",
      "0 129 555.5391845703125 1044.808837890625\n",
      "0 130 577.0475463867188 732.8704223632812\n",
      "0 131 400.47747802734375 738.0438232421875\n",
      "0 132 445.476318359375 1150.531982421875\n",
      "0 133 291.98321533203125 455.1485290527344\n",
      "0 134 194.48910522460938 499.5411071777344\n",
      "0 135 425.0657653808594 621.958740234375\n",
      "0 136 662.0267944335938 1307.4764404296875\n",
      "0 137 1116.203369140625 1579.580322265625\n",
      "0 138 298.69873046875 748.4971923828125\n",
      "0 139 239.9309844970703 717.9017333984375\n",
      "0 140 208.75997924804688 808.8998413085938\n",
      "0 141 378.4375305175781 1132.5804443359375\n",
      "0 142 177.91221618652344 498.4429626464844\n",
      "0 143 194.73721313476562 501.1069641113281\n",
      "0 144 250.8547821044922 648.9573364257812\n",
      "0 145 597.2522583007812 1941.3306884765625\n",
      "0 146 188.81227111816406 580.583251953125\n",
      "0 147 240.91371154785156 596.6435546875\n",
      "0 148 286.827392578125 550.5543212890625\n",
      "0 149 331.2696228027344 756.4200439453125\n",
      "0 150 168.34127807617188 471.3121643066406\n",
      "0 151 172.50653076171875 553.9854125976562\n",
      "0 152 129.84356689453125 642.2994384765625\n",
      "0 153 201.7637176513672 532.8890380859375\n",
      "0 154 250.2705841064453 735.4462280273438\n",
      "0 155 1373.750244140625 2443.9287109375\n",
      "0 156 517.8460693359375 3661.5419921875\n",
      "0 157 263.8106689453125 1551.0150146484375\n",
      "0 158 439.5955810546875 947.913818359375\n",
      "0 159 1183.447021484375 1401.9422607421875\n",
      "0 160 1066.0052490234375 1283.9515380859375\n",
      "0 161 1466.512451171875 1652.4503173828125\n",
      "0 162 952.0286865234375 1249.005615234375\n",
      "0 163 338.17755126953125 1565.4359130859375\n",
      "0 164 307.0252685546875 869.5726318359375\n",
      "0 165 756.9129638671875 2110.894287109375\n",
      "0 166 427.56732177734375 1380.7547607421875\n",
      "0 167 366.1797790527344 807.8736572265625\n",
      "0 168 273.62921142578125 507.4435119628906\n",
      "0 169 409.04559326171875 986.2994384765625\n",
      "0 170 391.58551025390625 1081.7525634765625\n",
      "0 171 171.77243041992188 593.1746826171875\n",
      "0 172 232.91595458984375 646.3961181640625\n",
      "0 173 265.18707275390625 554.5021362304688\n",
      "0 174 224.1458282470703 745.7401123046875\n",
      "0 175 288.4301452636719 1105.1077880859375\n",
      "0 176 282.3675842285156 621.2474365234375\n",
      "0 177 174.24630737304688 524.60107421875\n",
      "0 178 277.9413757324219 874.4299926757812\n",
      "0 179 153.73080444335938 636.6456298828125\n",
      "0 180 216.4694366455078 771.2236938476562\n",
      "0 181 388.9751281738281 841.804931640625\n",
      "0 182 429.8062438964844 1101.8983154296875\n",
      "0 183 228.19577026367188 659.2981567382812\n",
      "0 184 225.77613830566406 598.7557373046875\n",
      "0 185 254.74810791015625 722.2733154296875\n",
      "0 186 302.4500427246094 984.7392578125\n",
      "0 187 217.18482971191406 665.2953491210938\n",
      "0 188 289.99029541015625 804.0092163085938\n",
      "0 189 1282.1136474609375 2850.93212890625\n",
      "0 190 169.08413696289062 508.24017333984375\n",
      "0 191 226.3469696044922 433.0275573730469\n",
      "0 192 365.9790954589844 619.1452026367188\n",
      "0 193 207.7650604248047 634.2313232421875\n",
      "0 194 280.8732604980469 587.3209838867188\n",
      "0 195 353.1238708496094 769.0055541992188\n",
      "0 196 169.62167358398438 659.6669921875\n",
      "0 197 171.45399475097656 444.70489501953125\n",
      "0 198 403.0779724121094 835.7891845703125\n",
      "0 199 280.67608642578125 519.6344604492188\n",
      "0 200 190.9197235107422 525.267333984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 201 393.8295593261719 751.3467407226562\n",
      "0 202 281.01885986328125 595.609375\n",
      "0 203 292.3800964355469 979.6925048828125\n",
      "0 204 348.90704345703125 658.7974853515625\n",
      "0 205 201.24624633789062 701.2838134765625\n",
      "0 206 184.7581024169922 671.334716796875\n",
      "0 207 175.81675720214844 790.6422119140625\n",
      "0 208 155.28648376464844 598.1217041015625\n",
      "0 209 159.01846313476562 466.3292236328125\n",
      "0 210 241.9447479248047 691.3192138671875\n",
      "0 211 176.1152801513672 617.8717041015625\n",
      "0 212 215.55162048339844 636.6962280273438\n",
      "0 213 234.29225158691406 903.234130859375\n",
      "0 214 154.02273559570312 708.1536254882812\n",
      "0 215 262.8282775878906 860.488037109375\n",
      "0 216 185.61061096191406 558.8157348632812\n",
      "0 217 162.712646484375 447.9344482421875\n",
      "0 218 219.66116333007812 862.0879516601562\n",
      "0 219 191.2963104248047 522.5612182617188\n",
      "0 220 246.8496551513672 1028.738037109375\n",
      "0 221 172.50436401367188 868.4924926757812\n",
      "0 222 119.51495361328125 461.76507568359375\n",
      "0 223 98.54203033447266 419.6011047363281\n",
      "0 224 226.71450805664062 823.8058471679688\n",
      "0 225 192.29998779296875 768.5393676757812\n",
      "0 226 146.73619079589844 629.1600341796875\n",
      "0 227 100.81157684326172 390.61895751953125\n",
      "0 228 134.09140014648438 509.76727294921875\n",
      "0 229 74.28083801269531 359.46759033203125\n",
      "0 230 237.48403930664062 980.5376586914062\n",
      "0 231 114.31074523925781 391.8533630371094\n",
      "0 232 129.2451629638672 526.3783569335938\n",
      "0 233 158.8762664794922 716.9236450195312\n",
      "0 234 107.07477569580078 442.046875\n",
      "0 235 72.85856628417969 337.10791015625\n",
      "0 236 385.1562194824219 1888.1719970703125\n",
      "0 237 132.1160125732422 813.2853393554688\n",
      "0 238 133.18051147460938 604.2872924804688\n",
      "0 239 283.35260009765625 1739.1778564453125\n",
      "0 240 122.52152252197266 496.8363342285156\n",
      "0 241 215.57199096679688 742.5022583007812\n",
      "0 242 105.4435043334961 404.43902587890625\n",
      "0 243 437.8550720214844 770.1596069335938\n",
      "0 244 115.1288070678711 676.17041015625\n",
      "0 245 147.0375213623047 636.81396484375\n",
      "0 246 121.34078979492188 531.2625732421875\n",
      "0 247 123.32000732421875 539.98388671875\n",
      "0 248 141.18881225585938 570.0036010742188\n",
      "0 249 129.82266235351562 592.5181884765625\n",
      "0 250 121.38935852050781 536.7005004882812\n",
      "0 251 85.13619995117188 474.89642333984375\n",
      "0 252 130.730712890625 756.8518676757812\n",
      "0 253 128.07650756835938 637.5833740234375\n",
      "0 254 117.09077453613281 445.4129943847656\n",
      "0 255 145.30345153808594 630.228515625\n",
      "0 256 180.10324096679688 828.4729614257812\n",
      "0 257 161.05657958984375 687.4036254882812\n",
      "0 258 74.91886901855469 353.8540344238281\n",
      "0 259 121.72447204589844 558.5075073242188\n",
      "0 260 165.745361328125 731.1054077148438\n",
      "0 261 130.16990661621094 538.5458374023438\n",
      "0 262 171.34490966796875 777.674560546875\n",
      "0 263 96.50761413574219 532.79345703125\n",
      "0 264 274.23944091796875 1441.6319580078125\n",
      "0 265 120.43778228759766 690.1585083007812\n",
      "0 266 95.55992126464844 577.5307006835938\n",
      "0 267 97.84538269042969 635.688232421875\n",
      "0 268 99.66195678710938 485.03619384765625\n",
      "0 269 247.49551391601562 2854.57470703125\n",
      "0 270 416.4077453613281 5517.98095703125\n",
      "0 271 256.1368103027344 959.8789672851562\n",
      "0 272 225.06558227539062 1862.86865234375\n",
      "0 273 109.48863220214844 627.5509643554688\n",
      "0 274 136.10850524902344 774.7752685546875\n",
      "0 275 61.98933029174805 616.9012451171875\n",
      "0 276 177.5260772705078 1640.01904296875\n",
      "0 277 182.90162658691406 956.8673095703125\n",
      "0 278 142.73812866210938 618.1531372070312\n",
      "0 279 166.09605407714844 884.799560546875\n",
      "0 280 198.6748809814453 1237.443115234375\n",
      "0 281 71.4597396850586 547.4593505859375\n",
      "0 282 123.44771575927734 741.3294677734375\n",
      "0 283 181.8875274658203 799.4922485351562\n",
      "0 284 105.11386108398438 697.1917114257812\n",
      "0 285 110.6186294555664 799.3362426757812\n",
      "0 286 140.24951171875 581.9132080078125\n",
      "0 287 126.67325592041016 600.7351684570312\n",
      "0 288 143.34820556640625 506.554931640625\n",
      "0 289 140.3076934814453 863.6257934570312\n",
      "0 290 105.45291900634766 560.7860107421875\n",
      "0 291 108.67023468017578 1131.445068359375\n",
      "0 292 131.87301635742188 797.3756713867188\n",
      "0 293 92.11759948730469 596.935791015625\n",
      "0 294 89.07759857177734 666.024169921875\n",
      "0 295 63.3590202331543 533.0909423828125\n",
      "0 296 82.74263000488281 586.6004638671875\n",
      "0 297 179.15618896484375 1760.35693359375\n",
      "0 298 83.2374496459961 407.9795837402344\n",
      "0 299 85.71196746826172 571.0283203125\n",
      "0 300 80.49471282958984 537.185302734375\n",
      "0 301 471.5992126464844 2239.86572265625\n",
      "0 302 195.2832794189453 743.3859252929688\n",
      "0 303 168.5713348388672 867.9749145507812\n",
      "0 304 161.0154266357422 646.1431884765625\n",
      "0 305 181.5022430419922 859.7776489257812\n",
      "0 306 151.86273193359375 582.9569091796875\n",
      "0 307 172.6929168701172 622.8214111328125\n",
      "0 308 306.1510925292969 751.646728515625\n",
      "0 309 278.8533935546875 1099.1881103515625\n",
      "0 310 164.17117309570312 670.6742553710938\n",
      "0 311 212.97525024414062 889.7526245117188\n",
      "0 312 173.73301696777344 1094.169921875\n",
      "0 313 164.447509765625 781.002685546875\n",
      "0 314 115.59835815429688 753.9453735351562\n",
      "0 315 95.06788635253906 480.40008544921875\n",
      "0 316 188.85391235351562 1342.4736328125\n",
      "0 317 150.03335571289062 736.364013671875\n",
      "0 318 278.7513427734375 1819.281005859375\n",
      "0 319 78.18376922607422 500.71319580078125\n",
      "0 320 120.28951263427734 652.6455078125\n",
      "0 321 185.51466369628906 797.632080078125\n",
      "0 322 81.14360809326172 416.4730224609375\n",
      "0 323 127.23361206054688 583.1405639648438\n",
      "0 324 106.40464782714844 524.4765014648438\n",
      "0 325 235.52999877929688 1210.4378662109375\n",
      "0 326 148.1783447265625 709.5227661132812\n",
      "0 327 118.8704833984375 714.9613037109375\n",
      "0 328 174.18630981445312 849.6589965820312\n",
      "0 329 94.03730773925781 546.8629150390625\n",
      "0 330 126.84140014648438 821.3485107421875\n",
      "0 331 212.2609405517578 1003.8587036132812\n",
      "0 332 152.72763061523438 848.6847534179688\n",
      "0 333 75.3653564453125 424.1822204589844\n",
      "0 334 89.2661361694336 534.1121215820312\n",
      "0 335 140.11123657226562 996.8088989257812\n",
      "0 336 149.17398071289062 833.4107666015625\n",
      "0 337 142.7295379638672 641.05078125\n",
      "0 338 259.4819030761719 1129.182373046875\n",
      "0 339 164.18914794921875 793.3794555664062\n",
      "0 340 155.93310546875 650.7345581054688\n",
      "0 341 111.38211822509766 618.8211669921875\n",
      "0 342 243.13531494140625 1249.905029296875\n",
      "0 343 176.24937438964844 499.461181640625\n",
      "0 344 262.3482360839844 971.6826171875\n",
      "0 345 99.7232437133789 437.5384826660156\n",
      "0 346 251.49542236328125 687.4791259765625\n",
      "0 347 166.22457885742188 545.41015625\n",
      "0 348 151.53257751464844 771.9690551757812\n",
      "0 349 212.08441162109375 714.9884033203125\n",
      "0 350 130.0152587890625 598.3861694335938\n",
      "0 351 154.05535888671875 579.404541015625\n",
      "0 352 124.2193603515625 473.90667724609375\n",
      "0 353 186.98670959472656 1523.829345703125\n",
      "0 354 107.05143737792969 618.6028442382812\n",
      "0 355 111.26841735839844 810.2139892578125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3616ba19e9de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer_lag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss_lag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss_lag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer_lag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(lg)\n",
    "optimizer_lag=torch.optim.AdamW(model_lag.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "optimizer_naive=torch.optim.Adam(model_naive.parameters(), lr=5e-4)\n",
    "for t in range(5):\n",
    "    for i in range(dataset.num_train):\n",
    "        data=dataset.sample()\n",
    "        q,dq,ddq=get_info(data)\n",
    "        target=lg.inverse_model(model_generator,q,dq,ddq).detach()\n",
    "        \n",
    "        # Lagrangian network\n",
    "        tau=lg.inverse_model(model_lag,q,dq,ddq)\n",
    "        optimizer_lag.zero_grad()\n",
    "        loss_lag=crit(tau,target)\n",
    "        loss_lag.backward() \n",
    "        optimizer_lag.step()\n",
    "        \n",
    "        # Naive network\n",
    "        tau=model_naive(torch.cat([q,dq,ddq], axis=1))\n",
    "        optimizer_naive.zero_grad()\n",
    "        loss_naive=crit(tau,target)\n",
    "        loss_naive.backward()\n",
    "        optimizer_naive.step()\n",
    "        \n",
    "        print(t, i, loss_lag.data.item(), loss_naive.data.item())\n",
    "#         if i%1000==0:\n",
    "#             data=dataset.sample('valid')\n",
    "            \n",
    "#             q,dq,ddq=get_info(data)\n",
    "#             tau=lg.inverse_model(model_lag,q,dq,ddq)\n",
    "#             loss_val_lag=crit(tau,data[1].squeeze()*50)\n",
    "# #             train_loss_lag.append(loss_lag.data.item())\n",
    "# #             val_loss_lag.append(loss_val_lag.item())\n",
    "            \n",
    "#             # Naive network\n",
    "#             tau=model_naive(torch.cat([q,dq,ddq], axis=1))\n",
    "#             loss_val_naive=crit(tau,data[1].squeeze()*50)\n",
    "# #             train_loss_naive.append(loss_naive.data.item())\n",
    "# #             val_loss_naive.append(loss_val_naive.item())   \n",
    "            \n",
    "#             print('Val:', t, i, loss_val_lag.data.item() ,loss_val_naive.data.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feat\n",
      "feat.0\n",
      "feat.1\n",
      "feat.2\n",
      "feat.3\n",
      "diag\n",
      "diag.0\n",
      "tril\n",
      "gravity\n"
     ]
    }
   ],
   "source": [
    "for name, module in model_lag.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sequential(\n",
      "  (0): Linear(in_features=7, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (3): ReLU()\n",
      ")\n",
      "0 Linear(in_features=7, out_features=256, bias=True)\n",
      "1 ReLU()\n",
      "2 Linear(in_features=256, out_features=256, bias=True)\n",
      "3 ReLU()\n"
     ]
    }
   ],
   "source": [
    "for i,j in model_lag.feat.named_modules():\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00, -7.7214e+01,  1.3162e+01,  ...,  5.9595e+01,\n",
       "         -6.8283e-02, -2.4130e+02],\n",
       "        [ 0.0000e+00, -2.2030e+01,  4.2801e+01,  ...,  8.9456e+00,\n",
       "         -2.9239e-02, -1.8897e+01],\n",
       "        [ 0.0000e+00, -3.2994e+01, -5.4616e+01,  ..., -2.1125e+01,\n",
       "          1.3532e-01,  1.5908e+02],\n",
       "        ...,\n",
       "        [ 0.0000e+00, -7.7974e+02, -7.8320e+02,  ..., -1.6180e+02,\n",
       "         -5.2150e+00, -7.1043e+02],\n",
       "        [ 0.0000e+00, -3.9131e+01, -5.8152e+02,  ..., -5.6040e+01,\n",
       "         -5.8999e-03, -6.0449e+01],\n",
       "        [ 0.0000e+00, -1.1678e+02, -8.9093e+01,  ..., -3.7642e+01,\n",
       "         -1.3136e-04,  3.2812e+01]], device='cuda:3')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lag.diag[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [1., 4., 0.],\n",
      "        [2., 3., 9.]], device='cuda:3', grad_fn=<SelectBackward>)\n",
      "tensor([[[ 2.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 1.,  0.,  0.],\n",
      "         [ 0.,  8.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  2.,  0.],\n",
      "         [ 0.,  0.,  3.],\n",
      "         [ 0.,  0., 18.]]], device='cuda:3', grad_fn=<SelectBackward>)\n",
      "tensor([[ 2.,  0.,  0.],\n",
      "        [ 1.,  8.,  0.],\n",
      "        [ 2.,  3., 18.]], device='cuda:3', grad_fn=<SelectBackward>)\n",
      "tensor([[ 1.,  1.,  2.],\n",
      "        [ 1., 17., 14.],\n",
      "        [ 2., 14., 94.]], device='cuda:3', grad_fn=<SelectBackward>)\n",
      "tensor([[[  4.,   3.,   4.],\n",
      "         [  3.,   2.,   2.],\n",
      "         [  4.,   2.,   0.]],\n",
      "\n",
      "        [[  0.,   0.,   2.],\n",
      "         [  0.,  64.,  26.],\n",
      "         [  2.,  26.,   8.]],\n",
      "\n",
      "        [[  0.,   0.,   0.],\n",
      "         [  0.,   0.,  12.],\n",
      "         [  0.,  12., 342.]]], device='cuda:3', grad_fn=<SelectBackward>)\n",
      "tensor([[  4.,   3.,   6.],\n",
      "        [  3.,  66.,  40.],\n",
      "        [  6.,  40., 350.]], device='cuda:3', grad_fn=<SelectBackward>)\n",
      "tensor([ 24., 128., 366.], device='cuda:3', grad_fn=<SelectBackward>)\n",
      "tensor([  4.4247,  77.2517, 322.5732], device='cuda:3',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "class TestModule(nn.Module):\n",
    "    # Test module only for ndim=3\n",
    "    def __init__(self):\n",
    "        super(TestModule, self).__init__()\n",
    "        self.g=nn.Linear(3,3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y=torch.cat([torch.exp(x),torch.exp(2*x)],-1)\n",
    "        return y,self.g(x)\n",
    "reload(lg)\n",
    "\n",
    "torch.cuda.set_device('cuda:3')\n",
    "    \n",
    "model_L=TestModule().cuda()\n",
    "model_g=nn.Linear(3,3).cuda()\n",
    "q=torch.stack([torch.log(torch.arange(1,4).float()),torch.log(torch.arange(2,5).float()),torch.log(torch.arange(5,8).float()),torch.log(torch.arange(7,10).float())]).cuda()\n",
    "dq=torch.ones(q.shape).cuda()\n",
    "ddq=torch.ones(q.shape).cuda()\n",
    "\n",
    "L,dLdq,dLdt,H,dHdq,dHdt,quad,tau=lg.inverse_model(model_L.cuda(), q,dq,ddq, True)\n",
    "print(L[0])\n",
    "print(dLdq[0])\n",
    "print(dLdt[0])\n",
    "print(H[0])\n",
    "print(dHdq[0])\n",
    "print(dHdt[0])\n",
    "print(quad[0])\n",
    "print(tau[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
