# 1-27 计划

## Current objective

- [hard ddl] CSE 291 homework
    - A model-based RL paper and its revision 
    - so that I can start the optimization methods ...
- Mujoco - Environment:
    - cartpole, halfcheetah, humanoid, __pusher__, swimmer
        - we need to calibrate the force/reward of each environment: search for the parameters that minimize the distance between two environments .. if we have the same number of q value..
    - support ssh and off-screen render __DISPLAY=:1__ or xvbf-run to work
    - support cluster ...
- Robotics - Environment:
    - MovoPush/Pick with position control
    - Inverse Kinematics with RL/HER
    - RL optimizer for goal conditioned RL..
- Model free RL baselines...
    - Input: env, and a set of hyper-parameters.
    - Output:
        - model
        - reward curve
        - video
    - Algorithms:
        - DDPG/TD-3
        - ppo
        - sac
        - HER: we can borrow a multi processing implementation.. 
- Model based RL
    - Performance of trajectory optimization on
        - Other mujoco environment (__humanoid standup__)
        - Sapien
    - POPLIN as a good baseline, but we need to check if it works on other environment ...
- Others
    - Zhizuo: I should involve in that; but he is doing the homework..
    - Chutong: currently he felt bad about the optimization; he is trying to do the model learning.
    - Zhan: what should he do? Reimplement an robotics control algorithm..
    - Yingren: what's the progress ...
    - Yiran: what's the progress...


## Mujoco Environments
In this task, we should 1. run the environment on the ssh and render it to image. 2. run ppo/sac/TD3 and figure out the correct api on the server...

1. We first need add a timewrapper..

