最终还是只能宣告失败：
1. 过多的抽象带来的永远都是麻烦，还是只有纯粹的函数形式才方便
2. Dict是邪恶的，永远不要使用继承自dict的类（原因是因为我不想自己再维护一套复杂的语言
3. 如果一样事物设计起来比较复杂，那么就不要去设计，直到这个东西真正地被改变。
4. 用一个config类型存下必要的信息还是很有用的。

现在的问题在于：
我们需要对observation和action进行预处理。
然后再学基于这个的observation space。

还是按照之前一样，这个就叫做extension吧。
1. 一个encode_obs函数将state转化成网络的输出
    以及对应的inp_dim
2. 一个update函数来根据differences来对state进行update
    以及对应的difference dim
3. 一个distance函数

额外加入一个scene_space即可。














































## TODOs
应该处于也将长期处于复现工作中。

下一周的任务，理清其baseline，然后把手下的task全部接手。
学会submodule。

1. chutong的POLO，之后得花一周的时间去做做。
2. jinyu，我应给其提供task支持
3. yingren，我应该给其提供复现支持 （由于这是个测试，所以让他先玩玩
4. yiran，推箱子，和代码支持
5. Zhizuo 是否应该继续

一周之内出mujoco上的实验？
这三天主要做Model方面，GNN的baseline，方便跟jinyu zhao对接。

两周之内应该可以出个基本能看的结果？
Language as an Abstraction for Hierarchical Deep Reinforcement Learning/和Program Guided Agent这个，交给yingren去踩坑。

Yiran，推箱子不知道如何了，似乎可以先用这个试试？

